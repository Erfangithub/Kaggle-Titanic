{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main notebook for the Titanic project. In this notebook we will\n",
    "# preprocess the data for machine learning. Try different machine learning models\n",
    "# and select the best one. Also we will try different combinations of features\n",
    "# (or engineered features) to find the better set of features for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_data = 'train.csv'\n",
    "path_to_test_data = 'test.csv'\n",
    "\n",
    "train_total = pd.read_csv(path_to_train_data)\n",
    "test_total = pd.read_csv(path_to_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a test and validation set\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=80)\n",
    "\n",
    "for trainall_index, test_index in split.split(train_total, train_total[\"Survived\"]):\n",
    "    trainall = train_total.iloc[trainall_index]\n",
    "    test = train_total.iloc[test_index]\n",
    "    \n",
    "trainall = trainall.reset_index(drop = True)\n",
    "test = test.reset_index(drop = True)\n",
    "\n",
    "for train_index, val_index in split.split(trainall, trainall[\"Survived\"]):\n",
    "    train = trainall.iloc[train_index]\n",
    "    val = trainall.iloc[val_index]\n",
    "    \n",
    "train = train.reset_index(drop = True)\n",
    "val = val.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dennis, Mr. Samuel</td>\n",
       "      <td>male</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21172</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hamalainen, Master. Viljo</td>\n",
       "      <td>male</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250649</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Kent, Mr. Edward Austin</td>\n",
       "      <td>male</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11771</td>\n",
       "      <td>29.7000</td>\n",
       "      <td>B37</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Silvey, Mr. William Baird</td>\n",
       "      <td>male</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13507</td>\n",
       "      <td>55.9000</td>\n",
       "      <td>E44</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                           Name     Sex  \\\n",
       "0          321         0       3             Dennis, Mr. Samuel    male   \n",
       "1          756         1       2      Hamalainen, Master. Viljo    male   \n",
       "2          488         0       1        Kent, Mr. Edward Austin    male   \n",
       "3          435         0       1      Silvey, Mr. William Baird    male   \n",
       "4          731         1       1  Allen, Miss. Elisabeth Walton  female   \n",
       "\n",
       "     Age  SibSp  Parch     Ticket      Fare Cabin Embarked  \n",
       "0  22.00      0      0  A/5 21172    7.2500   NaN        S  \n",
       "1   0.67      1      1     250649   14.5000   NaN        S  \n",
       "2  58.00      0      0      11771   29.7000   B37        C  \n",
       "3  50.00      1      0      13507   55.9000   E44        S  \n",
       "4  29.00      0      0      24160  211.3375    B5        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#############################################################################################\n",
    "#############################################################################################\n",
    "# Creating classes to preprocess the data\n",
    "\n",
    "# Class for filling missing values\n",
    "class fillmiss(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, strategy):\n",
    "        self.columns = columns\n",
    "        self.strategy = strategy\n",
    "    def fit(self, X, y=None):\n",
    "        for ind, item in enumerate(self.columns):\n",
    "            misslen = sum(X[item].isnull())\n",
    "            if misslen >= 0:\n",
    "                if self.strategy[ind] == 'median':\n",
    "                    self.med = X[item].median()\n",
    "                if self.strategy[ind] == 'mode':\n",
    "                    self.mod = X[item].mode()        \n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        for ind, item in enumerate(self.columns):\n",
    "            misslen = sum(X[item].isnull())\n",
    "            if misslen > 0:\n",
    "                if self.strategy[ind] == 'median':\n",
    "                    X[item] = X[item].fillna(self.med)\n",
    "                if self.strategy[ind] == 'mode':\n",
    "                    X[item] = X[item].fillna(self.mod[0])\n",
    "        return X\n",
    "\n",
    "# Class for label encoding categorical variables\n",
    "\n",
    "class enclab(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        from sklearn import preprocessing\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        h = X\n",
    "        for ind, item in enumerate(self.columns):\n",
    "            loc = h.columns.get_loc(item)\n",
    "            tc = le.fit_transform(h[item])\n",
    "            h = h.drop(item,axis = 1)\n",
    "            h.insert(loc, item, tc)\n",
    "        return h\n",
    "\n",
    "# Class for adding two attributes\n",
    "\n",
    "class addattr(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, newcol):\n",
    "        self.columns = columns\n",
    "        self.newcol = newcol\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        X[self.newcol] = X[self.columns[0]] + X[self.columns[1]]\n",
    "        return X\n",
    "\n",
    "# Class for discretizing continuous data\n",
    "\n",
    "class disccont(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, newcols , intervals):\n",
    "        self.columns = columns\n",
    "        self.newcols = newcols\n",
    "        self.intervals = intervals\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        labelencoder = LabelEncoder()\n",
    "        for ind,item in enumerate(self.columns):\n",
    "            custom_bucket_array = np.array(self.intervals[ind])\n",
    "            X[self.newcols[ind]] = pd.cut(X[item], custom_bucket_array, labels = np.arange(len(self.intervals[ind])-1))\n",
    "        return X\n",
    "\n",
    "# Class for creating a Master. column\n",
    "\n",
    "class master(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        X['master'] = 0\n",
    "        for ind, item in enumerate(X['titles']):\n",
    "            if (item == 'Master'):\n",
    "                X.loc[ind,'master'] = 1\n",
    "        return X\n",
    "\n",
    "# Class for extracting titles from the Name column\n",
    "\n",
    "class title(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column, titles):\n",
    "        self.column = column\n",
    "        self.titles = titles\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        leng = len(X[self.column])\n",
    "        ser = pd.Series((-1*np.ones(leng)))\n",
    "        for item in self.titles:\n",
    "            for ind,row in enumerate(X[self.column]):\n",
    "                pos = row.find(item)\n",
    "                if pos != -1:\n",
    "                    ser[ind] = item\n",
    "        ser[ser == -1] = 'other'\n",
    "        \n",
    "        X['titles'] = ser\n",
    "        return X\n",
    "\n",
    "\n",
    "# Class for extracting lastnames from the Name column  \n",
    "\n",
    "class lastname(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        leng = len(X['Name'])\n",
    "        serr = pd.Series((-1*np.ones(leng)))\n",
    "        for ind,row in enumerate(X['Name']):\n",
    "            pos = row.find(',')\n",
    "            serr[ind] = row[:pos]\n",
    "        X.insert(0,\"lastname\", serr)\n",
    "        return X\n",
    "    \n",
    "# Class for Standard scaling a few columns in the dataframe\n",
    "\n",
    "class stsc(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols\n",
    "    def fit(self, X, y=None):\n",
    "        self.ss = StandardScaler()\n",
    "        self.ss.fit(X[self.cols])\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        X[self.cols] = self.ss.transform(X[self.cols])\n",
    "        return X\n",
    "\n",
    "# Class for dropping a few columns in the dataframe\n",
    "\n",
    "class dropcol(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,coldrop):\n",
    "        self.coldrop = coldrop\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        for item in self.coldrop:\n",
    "            if item in X.columns:\n",
    "                X = X.drop(item,axis=1)\n",
    "        return X    \n",
    "\n",
    "# Class for getting dummy variables\n",
    "\n",
    "class getdummy(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "        return X\n",
    "\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "# Some Classes that were NOT useful:\n",
    "\n",
    "# Extracting all the titles (this class by itself improves the results but\n",
    "# compared to the title class above it gives worse results)\n",
    "\n",
    "class titles(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        tser = []\n",
    "        for row in X['Name']:\n",
    "            pos1 = row.find(',')\n",
    "            pos2 = row.find('.')\n",
    "            tser.append(row[pos1+2:pos2])\n",
    "        X['titles'] = np.array(tser)\n",
    "        return X\n",
    "\n",
    "# Extracting deck from the Ticket column\n",
    "    \n",
    "class deck(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        ser = []\n",
    "        boo = X['Cabin'].isnull()\n",
    "        for item in X[~boo]['Cabin']:\n",
    "            ser.append(item[0])\n",
    "        X['deck'] = 1\n",
    "        ind1 = X.index[boo]\n",
    "        ind2 = X.index[~boo]\n",
    "        X.loc[ind1,'deck'] = None\n",
    "        X.loc[ind2,'deck'] = ser\n",
    "        return X\n",
    "\n",
    "# This class creates a column that is 1 when the passengers\n",
    "# have a nickname otherwise it is zero.\n",
    "\n",
    "class nickname(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        ser=[]\n",
    "        par='('\n",
    "        for item in X['Name']:\n",
    "            if item.find(par) != -1:\n",
    "                ser.append(1)\n",
    "            else:\n",
    "                ser.append(0)\n",
    "        X['nickname'] = ser\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "\n",
    "\n",
    "# Pipelines that had a positive effect on the machine learning process\n",
    "\n",
    "fmiss = fillmiss(columns = ['Embarked', 'Age', 'Fare'], strategy = ['mode', 'median', 'median'])\n",
    "\n",
    "el = enclab(['Sex','Embarked'])\n",
    "\n",
    "aattr = addattr(columns = ['SibSp','Parch'],newcol = 'famem')\n",
    "\n",
    "age60 = disccont(columns = [\"Age\"], newcols = [\"age60\"] , intervals = [[-1,60,200]])\n",
    "\n",
    "age0 = disccont(columns = [\"Age\"], newcols = [\"age0\"] , intervals = [[-1,5,200]])\n",
    "\n",
    "fare0 = disccont(columns = [\"Fare\"], newcols = ['fare0'] , intervals = [[-1,0.01,800]])\n",
    "\n",
    "fare300 = disccont(columns = [\"Fare\"], newcols = ['fare300'] , intervals = [[-1,300,800]])\n",
    "\n",
    "titlec = title(column = \"Name\", titles = ['Mr' , 'Mrs' , 'Miss' \n",
    "                                          , 'Dr', 'Master'])\n",
    "mtr = master()\n",
    "\n",
    "lname = lastname()\n",
    "\n",
    "ss = stsc(cols= ['Age','Fare'])\n",
    "\n",
    "drcol = dropcol(coldrop =['Survived','Name','PassengerId'])\n",
    "\n",
    "gdummy = getdummy()\n",
    "\n",
    "\n",
    "# pipelines that did not have any effect on the prediction score\n",
    "\n",
    "aattr = addattr(columns = ['SibSp','Parch'],newcol = 'famem')\n",
    "\n",
    "fared = disccont(columns = [\"Fare\"], newcols = ['fared'] , intervals = [[-1,0.01,25,50\n",
    "                                                                         ,75,100,300,800]])\n",
    "\n",
    "# pipelines that worsened the prediction score\n",
    "\n",
    "nkn = nickname()\n",
    "\n",
    "famem4 = disccont(columns = [\"famem\"], newcols = [\"famem4\"] , intervals = [[-1,3.5,12]])\n",
    "\n",
    "\n",
    "    #tls compared to titlec worsens the prediction score.\n",
    "tls = titles()\n",
    "\n",
    "dck = deck()\n",
    "\n",
    "\n",
    "# full pipeline\n",
    "\n",
    "full_pipeline = Pipeline([('fillmiss',fmiss) ,('enclab',el)\n",
    "                          , ('addattr', aattr)\n",
    "#                          ,('famem4', famem4)\n",
    "#                          , ('nkn',nkn)\n",
    "#                          , ('fared',fared)\n",
    "                          , ('age60', age60)\n",
    "                          , ('fare0', fare0),('fare300', fare300)\n",
    "                          , ('title',titlec)\n",
    "#                          , ('tls',tls)\n",
    "                          , ('master', mtr)\n",
    "                          , ('lastname', lname)\n",
    "#                          ,('deck',dck)\n",
    "                          , ('ss',ss)\n",
    "                          , ('drcol', drcol)\n",
    "                          , ('dummy', gdummy)\n",
    "                         ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transforming the train and validation sets\n",
    "\n",
    "trainm = full_pipeline.fit_transform(train.copy())\n",
    "valm = full_pipeline.transform(val.copy())\n",
    "\n",
    "# Transforming the trainall and test set\n",
    "\n",
    "trainallm = full_pipeline.fit_transform(trainall.copy())\n",
    "testm = full_pipeline.transform(test.copy())\n",
    "\n",
    "\n",
    "# Finding the common columns between trainm and valm datasets\n",
    "\n",
    "comcolval = list(set(trainm.columns)&set(valm.columns))\n",
    "\n",
    "trainm = trainm[comcolval]\n",
    "\n",
    "valm = valm[comcolval]\n",
    "\n",
    "# Finding the common columns between trainallm and testm datasets\n",
    "\n",
    "comcoltest = list(set(trainallm.columns)&set(testm.columns))\n",
    "\n",
    "trainallm = trainallm[comcoltest]\n",
    "\n",
    "testm = testm[comcoltest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "## Machine Learning\n",
    "\n",
    "# In this section we will try different machine learning models and pick the best one.\n",
    "# The result is that Support Vector Classifier with linear kernel gives the best\n",
    "# prediction score.\n",
    "# Hyper-parameter tuning is not shown here but only the selected parameters are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "########################################################################################\n",
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111888111888111"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Random Forests\n",
    "\n",
    "rf = RandomForestClassifier(max_features = 'sqrt', n_estimators = 1000,\n",
    "                               min_samples_split = 10, min_samples_leaf = 1,\n",
    "                            max_depth = 20, random_state=50)\n",
    "\n",
    "rf.fit(trainm.values,train['Survived'].values.ravel())\n",
    "\n",
    "ypredrf = rf.predict(valm.values)\n",
    "\n",
    "rf.score(valm.values,val['Survived'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8251748251748252"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Support Vector Classifier\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "svc.fit(trainm.values,train['Survived'].values.ravel())\n",
    "\n",
    "ypredsvc = svc.predict(valm.values)\n",
    "\n",
    "svc.score(valm.values,val['Survived'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762237762237763"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Gradient Boosting Classifier\n",
    "\n",
    "grbc = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.05,\n",
    "                                   max_depth=3, max_features='sqrt',\n",
    "                                   min_samples_leaf=10, \n",
    "                                   loss='deviance', random_state = 5)\n",
    "\n",
    "grbc.fit(trainm.values,train['Survived'].values.ravel())\n",
    "\n",
    "ypredgrbc = grbc.predict(valm.values)\n",
    "\n",
    "grbc.score(valm.values,val['Survived'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902097902097902"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################\n",
    "# extreme Gradient Boosting Classifier\n",
    "\n",
    "xg = XGBClassifier(colsample_bytree =0.2, gamma = 0.0468,reg_lambda=0.4,\n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                              reg_alpha = 0.15,\n",
    "                            n_estimators = 1000,subsample=0.525,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "xg.fit(trainm.values,train['Survived'].values.ravel())\n",
    "\n",
    "ypredxg = xg.predict(valm.values)\n",
    "\n",
    "xg.score(valm.values,val['Survived'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041958041958042"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Logisitc Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(trainm.values,train['Survived'].values.ravel())\n",
    "\n",
    "ypredlr = lr.predict(valm.values)\n",
    "\n",
    "lr.score(valm.values,val['Survived'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Stacking\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('svc', svc))\n",
    "level0.append(('rf',  rf))\n",
    "level0.append(('lr', lr))\n",
    "level0.append(('gb', grbc))\n",
    "level0.append(('xgb', xg))\n",
    "#level0.append(('lr', modellr))\n",
    "\n",
    "# define meta learner model\n",
    "#level1 = LogisticRegression()\n",
    "\n",
    "level1 = SVC(kernel = 'linear')\n",
    "\n",
    "# define the stacking ensemble\n",
    "stackmodel = StackingClassifier(estimators=level0, final_estimator=level1,\n",
    "                                cv=5)\n",
    "\n",
    "stackmodel.fit(trainm.values,train['Survived'].values.ravel())\n",
    "\n",
    "ypredstack = stackmodel.predict(valm.values)\n",
    "\n",
    "stackmodel.score(valm.values,val['Survived'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Averaging over different random splits of trainall into train and val.\n",
    "\n",
    "# There are some fluctuations in the validation scores for different random\n",
    "# splits of trainall therefore it is better to average over the score of different\n",
    "# random splits of the trainall set into train and val sets.\n",
    "\n",
    "rf = RandomForestClassifier(max_features = 'sqrt', n_estimators = 1000,\n",
    "                               min_samples_split = 10, min_samples_leaf = 1,\n",
    "                            max_depth = 20, random_state=50)\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "grbc = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=10, \n",
    "                                   loss='deviance', random_state = 5)\n",
    "\n",
    "xg = XGBClassifier(colsample_bytree =0.2, gamma = 0.047,reg_lambda=0.4,\n",
    "                             learning_rate=0.05, max_depth=4, \n",
    "                              reg_alpha = 0.15,\n",
    "                            n_estimators = 1000,subsample=0.525,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "model = svc # or any other model above like: rf, grbc, etc\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=i)\n",
    "\n",
    "    for train_index, val_index in split.split(trainall, trainall[\"Survived\"]):\n",
    "        train = trainall.iloc[train_index]\n",
    "        val = trainall.iloc[val_index]\n",
    "    \n",
    "    train = train.reset_index(drop = True)\n",
    "    val = val.reset_index(drop = True)\n",
    "    \n",
    "    trainm = full_pipeline.fit_transform(train.copy())\n",
    "    valm = full_pipeline.transform(val.copy())\n",
    "\n",
    "    comcolval = list(set(trainm.columns)&set(valm.columns))\n",
    "    trainm = trainm[comcolval]\n",
    "    valm = valm[comcolval]\n",
    "    \n",
    "    model.fit(trainm.values,train['Survived'].values.ravel())\n",
    "    scores.append(model.score(valm.values,val['Survived'].values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.array(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "########################################################################################\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547486033519553"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelt = svc\n",
    "\n",
    "modelt.fit(trainallm.values,trainall['Survived'].values.ravel())\n",
    "\n",
    "ypredtest = modelt.predict(testm.values)\n",
    "\n",
    "svc.score(testm.values,test['Survived'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "########################################################################################\n",
    "### Predicitons for submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_totalm = full_pipeline.fit_transform(train_total.copy())\n",
    "test_totalm = full_pipeline.transform(test_total.copy())\n",
    "\n",
    "\n",
    "comcoltot = list(set(train_totalm.columns)&set(test_totalm.columns))\n",
    "\n",
    "train_totalm = train_totalm[comcoltot]\n",
    "\n",
    "test_totalm = test_totalm[comcoltot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsvc = SVC(kernel = 'linear')\n",
    "\n",
    "modelsvc.fit(train_totalm.values,train_total['Survived'].values.ravel())\n",
    "\n",
    "ypredtotsvc = modelsvc.predict(test_totalm.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame()\n",
    "pred['PassengerId'] = test_total['PassengerId']\n",
    "pred['Survived'] = ypredtotsvc\n",
    "pred.to_csv('submissionsvc.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submitting the above file submissionsvc.csv to Kaggle gives an accuracy score of 79.425%\n",
    "# which puts the submission in the top 10% on the public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
